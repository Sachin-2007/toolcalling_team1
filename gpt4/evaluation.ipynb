{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bef7ad3e-59ae-4183-8889-c0715d9d548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import tiktoken\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "965a5f28-c6d2-4f35-a3a1-886107471512",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"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\"\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d5955958-efd9-4421-8d54-1ce32b4ad545",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class PromptTemplate:\n",
    "    def __init__(self, instructions, examples, query, tools_file='tools.json'):\n",
    "        self.instructions = instructions\n",
    "        self.tools_file = tools_file\n",
    "        self.tools = self._load_tools()\n",
    "        self.examples = examples\n",
    "        self.query = query\n",
    "        self.system_message = self._make_system_message()\n",
    "\n",
    "    def _load_tools(self):\n",
    "        try:\n",
    "            with open(self.tools_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except (FileNotFoundError, json.JSONDecodeError):\n",
    "            return {}\n",
    "        \n",
    "    def _make_system_message(self):\n",
    "        system_message = f'''{self.instructions}\n",
    "        \n",
    "        Tools (in JSON format):\n",
    "        {self.tools}\n",
    "        \n",
    "        Given input as a query, generate output as a list of the sub-questions and answers at each step. Also output a JSON as shown in examples.\n",
    "        Do not mention the sub-questions in the response. Carefully note the order in which arguments need to be given inside tools.\n",
    "        Example 1:\n",
    "        {self.examples[0]}\n",
    "        \n",
    "        Example 2 (when a tool requires output of a previous tool):\n",
    "        {self.examples[1]}\n",
    "        '''\n",
    "        return system_message\n",
    "\n",
    "    def get(self):\n",
    "        return {\n",
    "            \"system_message\": self.system_message,\n",
    "            \"user_message\": self.query\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "158c3bd5-ef96-4c56-a413-d336f846954f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class GPT4LLMHandler:\n",
    "    def __init__(self, api_key=os.environ['OPENAI_API_KEY'], model=\"gpt-4o-2024-08-06\", temperature=1, max_tokens=5000):\n",
    "        openai.api_key = api_key\n",
    "        self.client = openai.OpenAI()\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.price_per_1k_tokens = 0.0025\n",
    "\n",
    "    def _count_tokens(self, text):\n",
    "        encoding = tiktoken.get_encoding('o200k_base')\n",
    "        num_tokens = len(encoding.encode(text))\n",
    "        return num_tokens\n",
    "\n",
    "    def generate_response(self, system_message, user_message):\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            input_tokens = self._count_tokens(system_message) + self._count_tokens(user_message)\n",
    "\n",
    "            response = self.client.chat.completions.create(\n",
    "                        model=self.model,\n",
    "                        messages=[\n",
    "                            {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": system_message\n",
    "                                }\n",
    "                            ]\n",
    "                            },\n",
    "                            {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": user_message\n",
    "                                }\n",
    "                            ]\n",
    "                            }\n",
    "                        ],\n",
    "                        temperature=self.temperature,\n",
    "                        max_tokens=self.max_tokens,\n",
    "                        top_p=1,\n",
    "                        frequency_penalty=0,\n",
    "                        presence_penalty=0,\n",
    "                        response_format={\n",
    "                            \"type\": \"json_object\"\n",
    "                        }\n",
    "                        )\n",
    "\n",
    "            end_time = time.time()\n",
    "\n",
    "            output = response.choices[0].message.content\n",
    "            output_tokens = self._count_tokens(output)\n",
    "            total_tokens = input_tokens + output_tokens\n",
    "            total_cost = (total_tokens / 1000) * self.price_per_1k_tokens\n",
    "\n",
    "            self.log(user_message, output, input_tokens, output_tokens, total_cost, start_time, end_time)\n",
    "\n",
    "            return {\n",
    "                \"full\": response,\n",
    "                \"response\": output,\n",
    "                \"input_tokens\": input_tokens,\n",
    "                \"output_tokens\": output_tokens,\n",
    "                \"total_tokens\": total_tokens,\n",
    "                \"total_cost\": total_cost,\n",
    "                \"response_time\": end_time - start_time,\n",
    "                \"request_time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "        except:\n",
    "            return {\n",
    "                \"full\": response,\n",
    "                \"response\": output,\n",
    "                \"input_tokens\": input_tokens,\n",
    "                \"output_tokens\": output_tokens,\n",
    "                \"total_tokens\": total_tokens,\n",
    "                \"total_cost\": total_cost,\n",
    "                \"response_time\": end_time - start_time,\n",
    "                \"request_time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "716eaee6-2122-48ba-a9c2-02558ac427d4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "instructions = '''You are a query solver. You will be given tools. Using those tools, you have to solve the query. \n",
    "To solve the query, at each point, you have to ask sub-questions. These sub-questions are \"What is the next tool to use, its arguments and argument values?\". Look at answers to the previous sub-questions, which will give you context of how the current set of tools have been chosen so far. Compare this to the greater context, which is, how to solve the next question.\n",
    "\n",
    "Some important points :\n",
    "1) Tool description and argument description are very important. Read them to understand what exactly a certain tool generates as output or what inputs a tool can get.\n",
    "2) Output of tools in the previous step is input to tool for current statement. Compare descriptions, types and examples to get a huge clue.\n",
    "3) Always check if authentication tools like \"who_am_i\", \"team_id\", \"get_sprint_id\", etc. are needed at any point.\n",
    "4) Take care of \"type\" argument in \"works_list\" is issue, ticket or task are explicitly mentioned.\n",
    "5) You can access the output of the ith task using \"$$PREV[i]\". i starts from 0.\n",
    "6) Stop once you feel the task is complete and no further tools are needed to solve the query.\n",
    "7) To answer the query, you are only allowed to use the tools that we have provided.\n",
    "8) If the question is simply unsolvable using any tool we have, only return {\"tools: []}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "79647244-dc57-4ad3-aca7-61c7f60df917",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "examples = [{\n",
    "    \"tools\":\n",
    "    [\n",
    "        {\n",
    "            \"tool_name\": \"works_list\",\n",
    "            \"arguments\": [\n",
    "                {\n",
    "                    \"argument_name\": \"ticket_severity\",\n",
    "                    \"argument_value\": [\n",
    "                        \"blocker\"\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"argument_name\": \"type\",\n",
    "                    \"argument_value\": [\n",
    "                        \"ticket\"\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "},\n",
    "        {\n",
    "    \"tools\":\n",
    "        [\n",
    "            {\n",
    "                \"tool_name\": \"search_object_by_name\",\n",
    "                \"arguments\": [\n",
    "                    {\n",
    "                        \"argument_name\": \"query\",\n",
    "                        \"argument_value\": \"Globex\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"tool_name\": \"works_list\",\n",
    "                \"arguments\": [\n",
    "                    {\n",
    "                        \"argument_name\": \"created_by\",\n",
    "                        \"argument_value\": \"$$PREV[0]\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"argument_name\": \"ticket_severity\",\n",
    "                        \"argument_value\": [\n",
    "                            \"high\"\n",
    "                        ]\n",
    "                    },\n",
    "                    {\n",
    "                        \"argument_name\": \"type\",\n",
    "                        \"argument_value\": [\n",
    "                            \"ticket\"\n",
    "                            ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5f2308d9-9555-487c-a559-8b2eeed768f5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "llm = GPT4LLMHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "44381462-b314-44ed-bc8b-fa36584e5930",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_bleu_rouge(llm_response, ground_truth):\n",
    "    reference = [ground_truth.split()]\n",
    "    candidate = llm_response.split()\n",
    "    bleu_score = sentence_bleu(reference, candidate)\n",
    "\n",
    "    rouge = Rouge()\n",
    "    rouge_scores = rouge.get_scores(llm_response, ground_truth, avg=True)\n",
    "\n",
    "    return bleu_score, rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8f751d9b-a627-4b7d-b69e-4be5d0a420cc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with open('data.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4ab0768c-6019-4659-85c1-d238d9526c9f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in data:\n",
    "    prompt = PromptTemplate(instructions, examples, i['query'])\n",
    "    response = llm.generate_response(prompt.get()['system_message'], prompt.get()['user_message'])\n",
    "    llm_value = json.dumps(json.loads(response['response'])['tools'], sort_keys=False)\n",
    "    ground_truth = f'{i['solution']}'.replace(\"'\", '\"').replace('True', 'true')\n",
    "    bleu, rouge = evaluate_bleu_rouge(llm_value, ground_truth)\n",
    "    score = [llm_value, ground_truth, bleu, rouge]\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "236ec352-4647-4f3e-846c-28cc27f0a7ff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#bleu score\n",
    "sum = 0\n",
    "for i in scores:\n",
    "    sum+=i[2]\n",
    "bleu = sum/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ba8136b2-e5de-4b54-9d53-45bbb44dac35",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rl =  0\n",
    "for j in scores:\n",
    "    rl+=j[3]['rouge-l']['f']\n",
    "rl/=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2824d0f5-e8a7-48a4-b3a1-a758155ca5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu score: 0.7566116249817973\n",
      "Rouge-L F1 score: 0.9406528772091137\n"
     ]
    }
   ],
   "source": [
    "print('Bleu score:', bleu)\n",
    "print('Rouge-L F1 score:', rl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
